# 事务

## Transaction Log（Tlog）
* 记录了原始文档，用于索引恢复功能
* 在SolrCloud中，每个节点都有自己的tlog，在更新的时候，整个文档会写入tlog中
* 在原子更新（Atomic update）时，仍然是整个文档写进来，包括了从老文档中读取出来的内容，换言之，原子更新时，写到tlog的不是增量数据
* Tlog是保证一致性的关键，有了它，就算索引段（segment）关闭前JVM崩溃了，索引也不会丢失


## Hard commit
* 将数据持久化到磁盘里面，并且能够查询到这条数据
* 可以通过客户端显式调用实现，也可以通过在solrconfig.xml配置文件中添加相关配置实现
* 自动提交
    - maxTime参数表示每间隔多少毫秒就触发一次索引提交
    - maxDocs表示当队列中累计了多少个索引文档就触发一次索引提交
* 使用事务日志来获取最新的Document ID，同时对索引文件调用fsync方法确保索引数据写入到磁盘，并且保证即便在断电的极端情况下也不会造成数据丢失
* 要求所有的段文件必须立即合并为一个段文件，并重写整个索引，这个操作执行开销很大，不能执行太频繁。段文件合并应该合理配置合并策略，并定期执行索引优化，提升查询性能
* Hard commit被执行的时候
    - tlog会截断：当前 tlog 会关闭，一个新的 tlog 会开始，在已关闭的tlog中，如果较新的tlog超过了 100 个文档，则老的 tlog会删除掉
    - 当前正在索引的索引段会关闭，并flush
    - 可能会触发后台的段合并
    - openSearcher=true：Solr/Lucene searchers被重新打开，所有的cache都失效（译者注：索引段级别的cache不会失效），autowarming会执行。这是老版本唯一能看到新增加的文档的方法
    - openSearcher=false：除了以上四点以外没有其他动作了。如果要搜索新的文档，需要执行一次soft commit。


## openSearcher
* 选项的子属性，用来控制新提交的数据是否能被后来的搜索操作检索到（是否可见）


## Soft commit
* 软提交是比硬提交（openSearcher=true）使文档可见的更轻量级的操作，而且软提交不会结束当前索引段的构建
* Soft commit被执行的时候
    - tlog不会被截断，它会继续增长
    - 新增的文档会可见
    - 某些cache必须重新加载
    - 顶层的cache会失效
    - 新的索引段会生成


## fsynch
* 底层IO命令，当fsynch调用返回后，数据必定已写到了磁盘中


## recover
* 最后返回成功的更新调用已经将你的文档写到了集群中的tlog，默认是你的tlog已经flush，但是没有fsynch
* 当重启机器，它会联系leader节点，然后会执行其中一个恢复动作
    - 如果leader节点接收到小于等于100个文档，则会从它自己的tlog回放文档, 注意，在回放的过程中，新进来的文档会写到tlog的末尾，它们也会回放
    - 如果从节点下线到现在，leader节点接收了大于100个文档，则会采用传统的同步方式从leader节点同步整个索引


## 索引构建流程
* 写入的数据被一个节点接收，然后转交到正确的leader节点
* 从那个leader节点发送到所有相关分片的所有副本
* 所有副本索引完后回应leader节点
* leader节点回应一开始的接收节点
* 当所有的leader节点都回应之后，接收节点回应客户端，在这个点上，所有的数据都已经flush到了集群中的所有相关节点的tlog中
* 如果jvm崩溃了，文档也已经安全地写到了tlog中，但是，如果是操作系统奔溃，那就不一定了
    - 如果jvm崩溃（或者killed -9杀掉），然后重启，tlog会回放
    - 你可以修改solrconfig.xml里面的配置，在返回前用fsynch而不是flush，但这样是没有必要的。
    - 所有leaders和replicas同时因为硬件挂掉而丢失数据的几率是很小的。有些场景，就算存在细微的几率丢失数据也是不允许的，则可以采用这种牺牲吞吐量的方式


## 配置文件
### 硬提交
```
<!-- 自动(硬)提交策略 -->
<!-- autoCommit是硬提交, 开启后会进行如下操作: -->
<!-- 生成一个新的tlog文件, 删除旧的tlog文件; -->
<!-- 把内存中缓存的文档fsync(OS内部的函数)到磁盘中, 并创建一个index descriptor, 用来记录各个文档的存储位置;此时就算JVM奔溃或系统宕机, 也不影响这部分数据, 不利之处是: 占用资源较多; -->
<!-- 如果<openSearcher>true</openSearcher>, 就会打开查询器, 让此次硬提交的文档可供搜索；如果值设为true,则可以去掉softCommit -->
<autoCommit>
    <!-- 多少个文档提交一次: 要添加的文档数达到此值时自动触发新的提交 -->
    <maxDocs>${solr.autoCommit.maxDocs:1000}</maxDocs>
    <!-- 多少毫秒提交一次: 添加文档操作的时间持续到此值时自动触发新的提交, 与maxDocs配置其一即可 -->
    <maxTime>${solr.autoCommit.maxTime:1000}</maxTime>
    <!-- 如果为false, 提交操作会将最近的更改信息刷新到磁盘, 但不会立即打开查询器 - 也就是说客户端查询不到;
    实时性要求高的项目, 需要设置为true - 在6.0之后的版本中默认为true -->
    <openSearcher>true</openSearcher>
</autoCommit>
```

### 软提交
```
<!-- 软提交策略，配置后会进行如下操作 -->
<!-- 把内存中缓存的文档fsync(OS内部的函数)到磁盘中, 但不会创建index descriptor——也就是说各个文档的真实存储位置并没有被记录下来; -->
<!-- 打开文档查询器, 涉及到的索引数据可以被查询到——近实时(NRT)更好; -->
<!-- 软提交不会等待后台合并、整理文档等操作, 只确保了修改的可见行, 没有获取到文档的具体存储位置 —— 也就是说如果此时JVM奔溃或系统宕机, 就找不到这些数据了. -->
<!-- 软提交比硬提交更快, 更能做到近实时查询, 但是如果服务器不稳定, 或JVM奔溃, 会导致提交的数据无法被检索到. -->
<autoSoftCommit> 
    <maxTime>${solr.autoSoftCommit.maxTime:-1}</maxTime>
</autoSoftCommit>
```


## 用例分析
### 大批量索引构建
* 设置 soft commit 时间间隔足够长，比如 10 分钟或更长（配置为 -1 则不自动 soft commit）
* 大批量索引构建应该不是为了满足实时搜索的，所以没必要额外地打开任何类型的 searcher。
* 设置 hard commit 时间间隔为 15 秒，openSearcher=false。这里假设你只是为了把大量数据导入 solr，而不是为了实时搜索

### 索引更新很频繁，检索请求量很少
* 日志检索。这个场景下，每天有大量的日志要写进来，但是检索请求却很少，主要用作故障排除和日志分析
* 设置soft commit时间间隔足够长，设置为你能忍受新文档不可见的最长时间
* 设置 hard commit（openSearcher=false）的时间间隔为 15 秒

### 索引更新不频繁，检索请求量小或大
* 这是相对静止的索引，但时不时有一些更新操作。比如说 5-10 分钟有一个更新操作
* 除非近实时搜索是必需的功能，在这种场景下，我会去掉soft commit，每5分钟提交一次 hard commit（openSearcher=true）
* soft commit 和近实时搜索非常好用，但是并非没有代价的

### 索引更新很频繁，检索请求量大
* 这是近实时搜索的场景，是最复杂的场景
* 设置soft commit的时间间隔为你能忍受的最大长度
* 设置 hardcommit 的时间间隔为 15 秒

